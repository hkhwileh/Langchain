{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8697005,"sourceType":"datasetVersion","datasetId":5215740}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q -U langchain langchain-huggingface langchain_community chromadb faiss-cpu transformers accelerate bitsandbytes langchain_core bs4 pymupdf","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import sys\nimport pypdf\nfrom langchain_community.document_loaders import WebBaseLoader,PyMuPDFLoader # Data Ingestion\nimport bs4 # Beautiful Soup for webscraping\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter #Document split and create chunks\nfrom langchain_huggingface import HuggingFaceEmbeddings # Convert Doc into Vectors\nfrom langchain.vectorstores import Chroma # Vector Database to store vectors / docs\nfrom transformers import AutoTokenizer, AutoModelForCausalLM,BitsAndBytesConfig,pipeline # To load model and tokenizer\nimport torch\nfrom langchain_huggingface import HuggingFacePipeline # To Create Huggingface pipeline with langchain to create LLM Model\nfrom langchain.chains import RetrievalQA # To make Vector DB as Retriever\nfrom langchain_core.prompts import ChatPromptTemplate,PromptTemplate # To write prompt and template\nfrom langchain.chains.combine_documents import create_stuff_documents_chain # To combine LLM and Prompt and create chain\nfrom langchain.chains import create_retrieval_chain #To combine retriever and document chain for inferencing\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:02:56.232607Z","iopub.execute_input":"2024-06-15T11:02:56.233616Z","iopub.status.idle":"2024-06-15T11:02:56.240529Z","shell.execute_reply.started":"2024-06-15T11:02:56.233583Z","shell.execute_reply":"2024-06-15T11:02:56.239639Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:02:58.106085Z","iopub.execute_input":"2024-06-15T11:02:58.106873Z","iopub.status.idle":"2024-06-15T11:02:58.132779Z","shell.execute_reply.started":"2024-06-15T11:02:58.10684Z","shell.execute_reply":"2024-06-15T11:02:58.131915Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"text_document= PyMuPDFLoader('/kaggle/input/attention-research-paper/NIPS-2017-attention-is-all-you-need-Paper.pdf').load()","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:03:09.067674Z","iopub.execute_input":"2024-06-15T11:03:09.068067Z","iopub.status.idle":"2024-06-15T11:03:09.303725Z","shell.execute_reply.started":"2024-06-15T11:03:09.068039Z","shell.execute_reply":"2024-06-15T11:03:09.302909Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split Documents in chunks\ntext_splitter= RecursiveCharacterTextSplitter(chunk_size=3000,chunk_overlap=100)\ndocuments=text_splitter.split_documents(text_document)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:03:09.499429Z","iopub.execute_input":"2024-06-15T11:03:09.49999Z","iopub.status.idle":"2024-06-15T11:03:09.507036Z","shell.execute_reply.started":"2024-06-15T11:03:09.499948Z","shell.execute_reply":"2024-06-15T11:03:09.506079Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create Embeddings\nembedding_model_name= \"sentence-transformers/all-mpnet-base-v2\"\nembeddings= HuggingFaceEmbeddings(model_name=embedding_model_name)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:03:09.842313Z","iopub.execute_input":"2024-06-15T11:03:09.842938Z","iopub.status.idle":"2024-06-15T11:03:16.451177Z","shell.execute_reply.started":"2024-06-15T11:03:09.842909Z","shell.execute_reply":"2024-06-15T11:03:16.450328Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# create Vector DB, Store document and Embeddings in DB\ndb= Chroma.from_documents(documents=documents,embedding=embeddings,persist_directory='chroma_db')","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:03:16.452841Z","iopub.execute_input":"2024-06-15T11:03:16.453149Z","iopub.status.idle":"2024-06-15T11:03:19.040469Z","shell.execute_reply.started":"2024-06-15T11:03:16.453125Z","shell.execute_reply":"2024-06-15T11:03:19.039595Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Quantization and Load Model & Tokenizer\nbnb_config =BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type='nf4',\n    bnb_4bit_compute_dtype=torch.float16\n)\ntokenizer = AutoTokenizer.from_pretrained(\"Shorya22/LLaMA-2-7B\")\nmodel = AutoModelForCausalLM.from_pretrained(\"Shorya22/LLaMA-2-7B\",quantization_config=bnb_config,device_map='auto')","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:08:33.250053Z","iopub.execute_input":"2024-06-15T11:08:33.250669Z","iopub.status.idle":"2024-06-15T11:12:19.620449Z","shell.execute_reply.started":"2024-06-15T11:08:33.250639Z","shell.execute_reply":"2024-06-15T11:12:19.619455Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create pipeline using transformers\npipe= pipeline(task='text-generation',model=model,tokenizer=tokenizer,max_new_tokens=512,temperature=0.3,do_sample=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:13:43.360081Z","iopub.execute_input":"2024-06-15T11:13:43.36092Z","iopub.status.idle":"2024-06-15T11:13:43.366079Z","shell.execute_reply.started":"2024-06-15T11:13:43.360891Z","shell.execute_reply":"2024-06-15T11:13:43.365194Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# craete llm using Huggingface Pipeline\nllm= HuggingFacePipeline(pipeline=pipe)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:13:43.684374Z","iopub.execute_input":"2024-06-15T11:13:43.685062Z","iopub.status.idle":"2024-06-15T11:13:43.690479Z","shell.execute_reply.started":"2024-06-15T11:13:43.685032Z","shell.execute_reply":"2024-06-15T11:13:43.689537Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# RAG Without Prompt Template and Chain:","metadata":{}},{"cell_type":"code","source":"# Create retriever for query to model/llm\nretriever = db.as_retriever()\nqa= RetrievalQA.from_chain_type(llm=llm,retriever=retriever,verbose=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:13:44.212464Z","iopub.execute_input":"2024-06-15T11:13:44.21282Z","iopub.status.idle":"2024-06-15T11:13:44.490425Z","shell.execute_reply.started":"2024-06-15T11:13:44.212791Z","shell.execute_reply":"2024-06-15T11:13:44.489636Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Inferencing\nresult=qa.run('What is attention?')","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:13:44.579257Z","iopub.execute_input":"2024-06-15T11:13:44.579601Z","iopub.status.idle":"2024-06-15T11:14:21.075233Z","shell.execute_reply.started":"2024-06-15T11:13:44.579572Z","shell.execute_reply":"2024-06-15T11:14:21.074235Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('Answer:',result.split('Helpful Answer:')[-1])","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:14:21.077296Z","iopub.execute_input":"2024-06-15T11:14:21.077901Z","iopub.status.idle":"2024-06-15T11:14:21.082864Z","shell.execute_reply.started":"2024-06-15T11:14:21.077866Z","shell.execute_reply":"2024-06-15T11:14:21.082016Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# RAG Pipeline + Prompt Template + LLM Chain:","metadata":{}},{"cell_type":"code","source":"template = \"\"\"\nProvide answer in bullet Points.\nAlways end the answer with \"Thanks for asking!\".\n\nContext: {context}\\n\\n\\n\n\nQuestion: {input}\n\nResponse:\n\"\"\"\nprompt = PromptTemplate(template=template, input_variables=['context', 'input'])","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:14:21.084113Z","iopub.execute_input":"2024-06-15T11:14:21.084527Z","iopub.status.idle":"2024-06-15T11:14:21.095903Z","shell.execute_reply.started":"2024-06-15T11:14:21.084497Z","shell.execute_reply":"2024-06-15T11:14:21.095122Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create LLM Document Chain and merge llm and prompt\ndocument_chain= create_stuff_documents_chain(llm=llm,prompt=prompt)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:14:21.097882Z","iopub.execute_input":"2024-06-15T11:14:21.098174Z","iopub.status.idle":"2024-06-15T11:14:21.107023Z","shell.execute_reply.started":"2024-06-15T11:14:21.098152Z","shell.execute_reply":"2024-06-15T11:14:21.106176Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create retriver and retrival chain and merger retriever and llm document chain\nretriever = db.as_retriever()\nretrieval_chain= create_retrieval_chain(retriever=retriever,combine_docs_chain=document_chain)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:14:21.10799Z","iopub.execute_input":"2024-06-15T11:14:21.108255Z","iopub.status.idle":"2024-06-15T11:14:21.117997Z","shell.execute_reply.started":"2024-06-15T11:14:21.108233Z","shell.execute_reply":"2024-06-15T11:14:21.117224Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Inferencing\ninput_question= \"What is attention?\"\nresult=retrieval_chain.invoke({'input':input_question})","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:14:21.119231Z","iopub.execute_input":"2024-06-15T11:14:21.119617Z","iopub.status.idle":"2024-06-15T11:14:41.760546Z","shell.execute_reply.started":"2024-06-15T11:14:21.119585Z","shell.execute_reply":"2024-06-15T11:14:41.759553Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(result['answer'].split('\\n\\n\\n')[-1])","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:14:41.761668Z","iopub.execute_input":"2024-06-15T11:14:41.76194Z","iopub.status.idle":"2024-06-15T11:14:41.767437Z","shell.execute_reply.started":"2024-06-15T11:14:41.761915Z","shell.execute_reply":"2024-06-15T11:14:41.766536Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}